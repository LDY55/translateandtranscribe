"""
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å –ø—Ä—è–º–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π PyTorch
"""
import os
import sys
import subprocess
import io
from pathlib import Path
from pydub import AudioSegment
from tqdm import tqdm

class TranscriptionProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é Whisper"""
    
    def __init__(self):
        self.device = 'cpu'
        self.torch_dtype = None
        self.model = None
        self.processor = None
        self._check_and_install_deps()
        self._load_model()
    
    def _check_and_install_deps(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ PyTorch
            import torch
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu' 
            self.torch_dtype = torch.float16 if self.device == 'cuda' else torch.float32
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ transformers
            from transformers import WhisperForConditionalGeneration, WhisperProcessor
            
            print(f"‚úÖ PyTorch –Ω–∞–π–¥–µ–Ω. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
            
        except ImportError as e:
            print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {e}")
            print("üîÑ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch –∏ transformers...")
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ pip
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU-only –≤–µ—Ä—Å–∏—é PyTorch –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞
                subprocess.check_call([
                    sys.executable, "-m", "pip", "install", 
                    "torch", "transformers", "accelerate",
                    "--index-url", "https://download.pytorch.org/whl/cpu",
                    "--no-cache-dir"
                ], timeout=300)
                print("‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
                
                # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∏–º–ø–æ—Ä—Ç
                import torch
                from transformers import WhisperForConditionalGeneration, WhisperProcessor
                
                self.device = 'cpu'  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU
                self.torch_dtype = torch.float32
                
            except subprocess.TimeoutExpired:
                raise ImportError("–¢–∞–π–º-–∞—É—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
            except Exception as install_error:
                raise ImportError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {install_error}")
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper"""
        try:
            import torch
            from transformers import WhisperForConditionalGeneration, WhisperProcessor
            
            print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä—É—Å—Å–∫—É—é –º–æ–¥–µ–ª—å
            try:
                self.model = WhisperForConditionalGeneration.from_pretrained(
                    "antony66/whisper-large-v3-russian",
                    torch_dtype=self.torch_dtype,
                    low_cpu_mem_usage=True,
                    use_safetensors=True,
                ).to(self.device)
                
                self.processor = WhisperProcessor.from_pretrained("antony66/whisper-large-v3-russian")
                print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Ä—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å Whisper Large V3")
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä—É—Å—Å–∫–æ–π –º–æ–¥–µ–ª–∏: {e}")
                print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
                
                # Fallback –∫ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
                self.model = WhisperForConditionalGeneration.from_pretrained(
                    "openai/whisper-large-v3",
                    torch_dtype=self.torch_dtype,
                    low_cpu_mem_usage=True,
                    use_safetensors=True,
                ).to(self.device)
                
                self.processor = WhisperProcessor.from_pretrained("openai/whisper-large-v3")
                print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å Whisper Large V3")
                
        except Exception as e:
            raise Exception(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    
    def transcribe_file(self, file_path):
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
            
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –ø—É—Ç–µ–º –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        if not self.model or not self.processor:
            raise Exception("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        file_path = Path(file_path)
        
        try:
            import torch
            import numpy as np
            
            # –ß—Ç–µ–Ω–∏–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
            with open(file_path, "rb") as f:
                audio_bytes = f.read()
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞
            audio_format = file_path.suffix.lower().lstrip('.')
            if audio_format == 'mp3':
                audio = AudioSegment.from_mp3(io.BytesIO(audio_bytes))
            elif audio_format in ['wav', 'wave']:
                audio = AudioSegment.from_wav(io.BytesIO(audio_bytes))
            elif audio_format == 'flac':
                audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format='flac')
            elif audio_format in ['m4a', 'mp4']:
                audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format='mp4')
            else:
                raise Exception(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ: {audio_format}")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–æ–Ω–æ 16–∫–ì—Ü
            audio = audio.set_channels(1).set_frame_rate(16000)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy array
            audio_array = np.array(audio.get_array_of_samples(), dtype=np.float32)
            audio_array = audio_array / np.iinfo(np.int16).max  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            
            # –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —á–∞–Ω–∫–∏ –µ—Å–ª–∏ —Ñ–∞–π–ª –±–æ–ª—å—à–æ–π
            chunk_length = 30 * 16000  # 30 —Å–µ–∫—É–Ω–¥
            chunks = []
            
            if len(audio_array) <= chunk_length:
                chunks = [audio_array]
            else:
                for i in range(0, len(audio_array), chunk_length):
                    chunks.append(audio_array[i:i + chunk_length])
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —á–∞–Ω–∫–æ–≤
            all_text = []
            for i, chunk in enumerate(tqdm(chunks, desc="–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è")):
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                inputs = self.processor(chunk, sampling_rate=16000, return_tensors="pt")
                input_features = inputs.input_features.to(self.device)
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
                with torch.no_grad():
                    predicted_ids = self.model.generate(
                        input_features,
                        max_length=448,
                        num_beams=5,
                        early_stopping=True,
                        return_dict_in_generate=True
                    )
                
                # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
                transcription = self.processor.batch_decode(
                    predicted_ids.sequences, 
                    skip_special_tokens=True
                )[0]
                
                all_text.append(transcription.strip())
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            final_text = " ".join(all_text)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            output_file = file_path.with_suffix('.txt')
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(final_text)
            
            return {
                'text': final_text,
                'output_file': str(output_file),
                'success': True
            }
            
        except Exception as e:
            return {
                'text': '',
                'output_file': '',
                'success': False,
                'error': str(e)
            }
    
    def get_model_info(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if self.model:
            return {
                'model_loaded': True,
                'device': self.device,
                'torch_dtype': str(self.torch_dtype)
            }
        else:
            return {
                'model_loaded': False,
                'device': None,
                'torch_dtype': None
            }